{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "graph = pickle.load(file=open('graph.pickle', 'rb'))\n",
    "index = pickle.load(file=open('index.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def create_matrix(clean_graph, index):\n",
    "    matrix = np.zeros((len(clean_graph), len(clean_graph)))\n",
    "    for word in tqdm(clean_graph.keys()):\n",
    "        for wd in clean_graph[word].keys():\n",
    "            matrix[index[word], index[wd]] = clean_graph[word][wd]\n",
    "    return matrix\n",
    "\n",
    "matrix = create_matrix(graph, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import MiniBatchSparsePCA\n",
    "\n",
    "pca = MiniBatchSparsePCA(n_components=100, batch_size=1000, normalize_components=True)\n",
    "pca.fit(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('graph.json', 'w') as outfile:\n",
    "    json.dump(graph, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('graph.json', 'r') as file:\n",
    "    a = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 248804/248804 [00:18<00:00, 13362.22it/s]\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "def create_sparse_matrix(clean_graph, index):\n",
    "    data = []\n",
    "    row = []\n",
    "    col = []\n",
    "    for word in tqdm(clean_graph.keys()):\n",
    "        for wd in clean_graph[word].keys():\n",
    "            row.append(index[word])\n",
    "            col.append(index[wd])\n",
    "            data.append(clean_graph[word][wd])\n",
    "    matrix = csr_matrix((data, (row, col)))\n",
    "    return matrix\n",
    "matrix = create_sparse_matrix(graph, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(248804, 248804)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = matrix.shape\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import IncrementalPCA\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "chunk_size = 100\n",
    "n = matrix.shape[0]\n",
    "\n",
    "pca = IncrementalPCA(n_components=15, batch_size=100)\n",
    "\n",
    "for i in tqdm(range(0, n//chunk_size)):\n",
    "    rows = matrix[i*chunk_size : (i+1)*chunk_size].toarray()\n",
    "    pca.partial_fit(rows)\n",
    "\n",
    "pickle.dump(file=open('pca.pickle', 'wb'), obj=pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TruncatedSVD(algorithm='randomized', n_components=100, n_iter=5,\n",
       "       random_state=0, tol=0.0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=100, random_state=0)\n",
    "\n",
    "svd.fit(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfo_svd = svd.transform(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(file=open('svd.pickle', 'wb'), obj=svd)\n",
    "pickle.dump(file=open('svd_transfo.pickle', 'wb'), obj=transfo_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator IncrementalPCA from version 0.20.3 when using version 0.20.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "pca = pickle.load(open(\"dac/pca.pickle\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfo = pca.transform(matrix[0:1000].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "a = datetime.datetime.now()\n",
    "kmeans = KMeans(n_clusters=10, random_state=0)\n",
    "b = datetime.datetime.now()\n",
    "print(b-a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.fit(transfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = kmeans.predict(transfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "a = Counter(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.zeros(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_clusters_index(index, clusters):\n",
    "    clusters_index = {}\n",
    "    for word, row in index.values():\n",
    "        clusters_index[word] = clusters[row]\n",
    "    return clusters_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def book_to_vect(clusters_index, n_clusters, book):\n",
    "    \"\"\"\n",
    "    kmeans is an index of kmeans[word] = cluster_id\n",
    "    \"\"\"\n",
    "    vect = np.zeros(n_clusters)\n",
    "    for word in book.author:\n",
    "        if word in clusters_index.keys():\n",
    "            vect[clusters_index[word]] += 1\n",
    "    for word in book.title:\n",
    "        if word in clusters_index.keys():\n",
    "            vect[clusters_index[word]] += 1\n",
    "    vect = np.linalg.norm(vect)\n",
    "    return vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [4,5,3,7,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
